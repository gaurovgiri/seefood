{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train'\n",
    "test_dir = 'dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0,1), (0,1))])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chatamari', 'chhoila', 'dalbhat', 'dhindo', 'gundruk', 'kheer', 'momo', 'sekuwa', 'selroti']\n"
     ]
    }
   ],
   "source": [
    "classes = trainloader.dataset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "std evaluated to zero after conversion to torch.float32, leading to division by zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gaurav/Codes/seefood/model.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gaurav/Codes/seefood/model.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gaurav/Codes/seefood/model.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/gaurav/Codes/seefood/model.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     plt\u001b[39m.\u001b[39mimshow(trainset[i][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gaurav/Codes/seefood/model.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     plt\u001b[39m.\u001b[39mtitle(classes[trainset[i][\u001b[39m1\u001b[39m]])\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torchvision/datasets/folder.py:231\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(sample)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torchvision/transforms/functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    361\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/Codes/seefood/venv/lib64/python3.11/site-packages/torchvision/transforms/_functional_tensor.py:923\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    921\u001b[0m std \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(std, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    922\u001b[0m \u001b[39mif\u001b[39;00m (std \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 923\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstd evaluated to zero after conversion to \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m, leading to division by zero.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    924\u001b[0m \u001b[39mif\u001b[39;00m mean\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    925\u001b[0m     mean \u001b[39m=\u001b[39m mean\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: std evaluated to zero after conversion to torch.float32, leading to division by zero."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
